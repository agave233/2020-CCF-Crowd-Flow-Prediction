{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "type2eng = {'旅游景点;公园': 'Attraction;Park', '教育培训;高等院校': 'Education;School', '购物;购物中心': 'Shopping;Mall', '医疗;综合医院': 'Medical;Hospital', '运动健身;体育场馆': 'Sport;Stadium', '旅游景点;文物古迹': 'Attraction;Monument', '旅游景点;风景区': 'Attraction;Scenic', '交通设施;火车站': 'Transportation;Train', '交通设施;长途汽车站': 'Transportation;Bus', '旅游景点;植物园': 'Attraction;Arboretum', '旅游景点;游乐园': 'Attraction;Amusement', '旅游景点;水族馆': 'Attraction;Aquarium', '旅游景点;动物园': 'Attraction;Zoo', '交通设施;飞机场': 'Transportation;Airport'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 997 areas data\n",
    "area_info = pd.read_csv('./data/area_passenger_info.csv', names=['id','name','type','center_x','center_y','grid_x','grid_y','area'])\n",
    "area_info['type'] = area_info[['type']].apply(lambda x: type2eng[x['type']], axis=1)\n",
    "area_flow = pd.read_csv('./data/area_passenger_index.csv', names=['id','date_hour','flow'])\n",
    "weather = pd.read_csv('./data/weather_data.csv', names=['date','weekday','high','low','weather'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>flow</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-17 00:00:00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-17 01:00:00</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-17 02:00:00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-17 03:00:00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-17 04:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           date_hour  flow  day  hour\n",
       "0   1 2020-01-17 00:00:00   1.8    0     0\n",
       "1   1 2020-01-17 01:00:00   1.5    0     1\n",
       "2   1 2020-01-17 02:00:00   1.3    0     2\n",
       "3   1 2020-01-17 03:00:00   1.3    0     3\n",
       "4   1 2020-01-17 04:00:00   1.7    0     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_flow['date_hour'] = pd.to_datetime(area_flow['date_hour'],format='%Y%m%d%H')\n",
    "area_flow['day'] = area_flow['date_hour'].dt.day.apply(lambda x:x-17 if x>=17 else x+14)\n",
    "area_flow['hour'] = area_flow['date_hour'].dt.hour\n",
    "area_flow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>wea_encoded</th>\n",
       "      <th>day</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday  high  low  wea_encoded  day  weekend\n",
       "0        5     3   -7            1    0        0\n",
       "1        6    -2   -4            1    1        1\n",
       "2        7     5   -4            0    2        1\n",
       "3        1     6   -7            0    3        0\n",
       "4        2     4   -6            0    4        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wea = {'中雪':2, '多云':0, '小雨':2, '小雪':2, '晴':0, '暴雪':2, '阴':1, '雨夹雪':2, '雾':1, '霾':1}\n",
    "\n",
    "weather['weather'] = weather['weather'].apply(lambda x: x if '~' in x else x+'~'+x)\n",
    "weather['wea1'], weather['wea2'] = weather['weather'].str.split('~', 1).str\n",
    "weather_df = weather.drop(['weather'], axis=1)\n",
    "weather_df['wea1_encoded'] = weather_df['wea1'].map(dict_wea)\n",
    "weather_df['wea2_encoded'] = weather_df['wea2'].map(dict_wea)\n",
    "weather_df['wea_encoded'] = weather_df.apply(lambda x: max(x['wea1_encoded'],x['wea2_encoded']), axis=1)\n",
    "weather_df['day'] = range(weather_df.shape[0])\n",
    "weather_df['weekend'] = weather_df['weekday'].apply(lambda x: 1 if x > 5 else 0)\n",
    "\n",
    "weather_df.drop(['date','wea2_encoded','wea1_encoded','wea1','wea2'],axis=1,inplace=True)\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree model: xgoost & lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_xgboost(train_data, train_y):\n",
    "    model_xgb = xgb.XGBRegressor(max_depth=5\n",
    "                                ,learning_rate=0.14\n",
    "                                ,n_estimators=2000\n",
    "                                ,n_jobs=-1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    model_xgb.fit(train_data,train_y)\n",
    "    print('training time:', str(int(time.time()-t1))+'s, ', end='')\n",
    "    return model_xgb\n",
    "\n",
    "def training_lightgbm(train_data, train_y):\n",
    "    model_lgb = lgb.LGBMRegressor(num_leaves=20\n",
    "                                ,max_depth=5\n",
    "                                ,learning_rate=0.14\n",
    "                                ,n_estimators=2000\n",
    "                                ,n_jobs=-1)\n",
    "\n",
    "    t1 = time.time()\n",
    "    model_lgb.fit(train_data,train_y)\n",
    "    print('training time:', str(int(time.time()-t1))+'s, ', end='')\n",
    "    return model_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(flow_data_in, split_day, area_embed=[], weekday=False, model='xgboost'):\n",
    "\n",
    "    flow_data_in = pd.merge(flow_data_in, weather_df, on='day')\n",
    "    flow_data_in = pd.merge(flow_data_in, area_info[['id','area','type']], on='id')\n",
    "    \n",
    "    # graph embedding feature\n",
    "    if len(area_embed) != 0:\n",
    "        flow_data_in = pd.merge(flow_data_in, area_embed, on='id')\n",
    "\n",
    "    # if only weekday or not\n",
    "    if weekday:\n",
    "        flow_data_in = flow_data_in[flow_data_in['weekend'] == 0]\n",
    "        if split_day >= 30 and model == 'xgboost':\n",
    "            flow_data_in = flow_data_in[flow_data_in['day'] != 28] # notice: it's a bug !\n",
    "    \n",
    "    # history flow feature\n",
    "    flow_data_in['flow_1db'] = [0]*1 + flow_data_in['flow'][:-1].tolist()\n",
    "    flow_data_in['flow_2db'] = [0]*2 + flow_data_in['flow'][:-2].tolist()\n",
    "    flow_data_in['flow_3db'] = [0]*3 + flow_data_in['flow'][:-3].tolist()\n",
    "    flow_data_in['flow_3dba'] = flow_data_in[['flow_1db','flow_2db','flow_3db']].mean(axis=1)\n",
    "\n",
    "    # yesterday feature\n",
    "    flow_data_in['wea_1db'] = [0] + flow_data_in['wea_encoded'][:-1].tolist()\n",
    "    flow_data_in['low_1db'] = [0] + flow_data_in['low'][:-1].tolist()\n",
    "    flow_data_in['week_1db'] = [0] + flow_data_in['weekend'][:-1].tolist()\n",
    "\n",
    "    # # type & id encode\n",
    "    dict_type = dict(flow_data_in[flow_data_in['day']<split_day].groupby(['type']).mean()['flow'])\n",
    "    dict_id = dict(flow_data_in[flow_data_in['day']<split_day].groupby(['id']).mean()['flow'])\n",
    "    flow_data_in['type'] = flow_data_in['type'].map(dict_type)\n",
    "    flow_data_in['id'] = flow_data_in['id'].map(dict_id)\n",
    "\n",
    "    flow_data_out = flow_data_in[flow_data_in['day']>15]\n",
    "    flow_data_out.drop(['weekday','high'],axis=1,inplace=True)\n",
    "    \n",
    "    return flow_data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. base flow for RULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6979, 12) (6979,) (6979, 15)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-1 validation\n",
    "'''\n",
    "flow_data = area_flow.groupby(['id','day']).agg(['mean'])['flow'].reset_index()\n",
    "flow_data = flow_data.rename(columns={'mean':'flow'})\n",
    "flow_data = feature_extraction(flow_data, 23)\n",
    "\n",
    "valid_data = flow_data[flow_data['day']>=23]\n",
    "train_data = flow_data[flow_data['day']<23]\n",
    "train_y = train_data['flow']\n",
    "\n",
    "train_data.drop(['flow','flow_3db','flow_2db'],axis=1,inplace=True)\n",
    "print(train_data.shape, train_y.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 11s, xgboost validation score:  0.2638492460322465\n",
      "training time: 1s, lightgbm validation score:  0.2726078988166893\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-1 validation\n",
    "'''\n",
    "day_data = valid_data[valid_data['day']==23]\n",
    "day_y = day_data['flow']\n",
    "day_data.drop(['flow','flow_2db','flow_3db'],axis=1,inplace=True)\n",
    "\n",
    "# xgboost\n",
    "model_xgb_forbase_val = training_xgboost(train_data, train_y)\n",
    "day_flow = model_xgb_forbase_val.predict(day_data)\n",
    "day_flow[day_flow<0] = 0\n",
    "print('xgboost validation score: ', 1/(mean_squared_error(day_y, day_flow)**0.5+1))\n",
    "\n",
    "# lightgbm\n",
    "model_lgb_forbase_val = training_lightgbm(train_data, train_y)\n",
    "day_flow = model_lgb_forbase_val.predict(day_data)\n",
    "day_flow[day_flow<0] = 0\n",
    "print('lightgbm validation score: ', 1/(mean_squared_error(day_y, day_flow)**0.5+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13958, 12) (13958,) (8973, 15)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-2 prediction\n",
    "'''\n",
    "test_data = pd.read_csv('./data/test_submit_example.csv', names=['id','date','flow'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'],format='%Y%m%d%H')\n",
    "test_data['day'] = test_data['date'].dt.day.apply(lambda x:x+14)\n",
    "test_data.drop(['date'],axis=1,inplace=True)\n",
    "\n",
    "area_flow_all = pd.concat([area_flow[['id','day','flow']], test_data])\n",
    "flow_data = area_flow_all.groupby(['id','day']).agg(['mean'])['flow'].reset_index()\n",
    "flow_data = flow_data.rename(columns={'mean':'flow'})\n",
    "flow_data = feature_extraction(flow_data, 30)\n",
    "\n",
    "test_data = flow_data[flow_data['day']>=30]\n",
    "train_data = flow_data[flow_data['day']<30]\n",
    "train_y = train_data['flow']\n",
    "train_data.drop(['flow','flow_3db','flow_2db'],axis=1,inplace=True)\n",
    "\n",
    "print(train_data.shape, train_y.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 22s, training time: 1s, "
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-2 prediction\n",
    "'''\n",
    "day_data = test_data[test_data['day']==30]\n",
    "day_y = day_data['flow']\n",
    "day_data.drop(['flow','flow_2db','flow_3db'],axis=1,inplace=True)\n",
    "\n",
    "# xgboost\n",
    "model_xgb_forbase = training_xgboost(train_data, train_y)\n",
    "day_flow_xgb = model_xgb_forbase.predict(day_data)\n",
    "day_flow_xgb[day_flow_xgb<0] = 0\n",
    "\n",
    "# lightgbm\n",
    "model_lgb_forbase = training_lightgbm(train_data, train_y)\n",
    "day_flow_lgb = model_lgb_forbase.predict(day_data)\n",
    "day_flow_lgb[day_flow_lgb<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1-3 save the result of base\n",
    "'''\n",
    "with open('./cache/base_lgb.pkl', 'wb') as f:\n",
    "    pkl.dump(day_flow_lgb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. hour-level flow prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_level_flow_prediction(model='lightgbm', mode='valid', weekday=False):\n",
    "    '''\n",
    "    mode: valid or predict\n",
    "    '''\n",
    "    \n",
    "    pred_res = {}\n",
    "    for hour in range(24):\n",
    "        with open('./cache/area_embedding_1/area_flow_hour_node2vec_embed_es16_wl5_'+str(hour)+'.pkl','rb') as f:\n",
    "            hour_embed = pkl.load(f)\n",
    "        if model == 'xgboost' or weekday == False:\n",
    "            with open('./cache/area_embedding_0/area_flow_hour_embed_'+str(hour)+'.pkl','rb') as f:\n",
    "                hour_embed = pkl.load(f)\n",
    "\n",
    "        hour_embed = {int(k)+1:v for k,v in hour_embed.items()}\n",
    "        area_embed = pd.DataFrame.from_dict(hour_embed,orient='index').reset_index().rename(columns = {'index':'id'})\n",
    "\n",
    "        if mode == 'valid':\n",
    "            split_day = 23\n",
    "            flow_data = area_flow[area_flow['hour']==hour][['id','flow','day']]\n",
    "        if mode == 'predict':\n",
    "            split_day = 30\n",
    "            test_data = pd.read_csv('./data/test_submit_example.csv', names=['id','date','flow'])\n",
    "            test_data['date'] = pd.to_datetime(test_data['date'],format='%Y%m%d%H')\n",
    "            test_data['day'] = test_data['date'].dt.day.apply(lambda x:x+14)\n",
    "            test_data['hour'] = test_data['date'].dt.hour\n",
    "            test_data = test_data[test_data['hour']==hour][['id','flow','day']]\n",
    "            area_flow_1 = area_flow[area_flow['hour']==hour][['id','flow','day']]\n",
    "            flow_data = pd.concat([area_flow_1, test_data]).sort_values(['id','day'])\n",
    "        \n",
    "        predict_len = 5 if weekday else 7\n",
    "        split_day = split_day + 1 if weekday else split_day\n",
    "        flow_data = feature_extraction(flow_data, split_day, area_embed, weekday, model)\n",
    "\n",
    "        test_data = flow_data[flow_data['day']>=split_day]\n",
    "        train_data = flow_data[flow_data['day']<split_day]\n",
    "        train_y = train_data['flow']\n",
    "        train_data.drop(['flow','flow_3db','flow_2db'],axis=1,inplace=True)\n",
    "\n",
    "        if model == 'lightgbm':\n",
    "            model_tree = training_lightgbm(train_data, train_y)\n",
    "        if model == 'xgboost':\n",
    "            model_tree = training_xgboost(train_data, train_y)\n",
    "\n",
    "        scores = []\n",
    "        pred_flow = []\n",
    "        for day in range(split_day, split_day + predict_len):\n",
    "            day_data = test_data[test_data['day']==day]\n",
    "            if len(day_data) == 0:\n",
    "                continue\n",
    "            day_data['flow_3dba'] = day_data[['flow_1db','flow_2db','flow_3db']].mean(axis=1)\n",
    "            day_y = day_data['flow']\n",
    "            day_data.drop(['flow','flow_2db','flow_3db'],axis=1,inplace=True)\n",
    "            day_flow = model_tree.predict(day_data)\n",
    "\n",
    "            day_flow[day_flow<0] = 0\n",
    "            pred_flow.append(day_flow)\n",
    "\n",
    "            if mode == 'valid':\n",
    "                scores.append(mean_squared_error(day_y, day_flow))\n",
    "\n",
    "            if day < split_day + predict_len - 1:\n",
    "                test_data.loc[test_data['day']==day+1,'flow_3db'] = test_data[test_data['day']==day]['flow_2db'].tolist()\n",
    "                test_data.loc[test_data['day']==day+1,'flow_2db'] = test_data[test_data['day']==day]['flow_1db'].tolist()\n",
    "                test_data.loc[test_data['day']==day+1,'flow_1db'] = day_flow\n",
    "\n",
    "        pred_res[hour] = {'pred_flow':np.array(pred_flow)}\n",
    "        if mode == 'valid':\n",
    "            scores = np.array(scores)\n",
    "            print(hour, round(1/(scores.mean()**0.5+1), 6))\n",
    "            pred_res[hour]['score'] = scores\n",
    "\n",
    "    return pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_score(pred_res, predict_len=7):\n",
    "    day_s = [0]*predict_len\n",
    "    for k, v in pred_res.items():\n",
    "        for i in range(predict_len):\n",
    "            day_s[i] += v['score'][i]\n",
    "            \n",
    "    for i in range(predict_len):\n",
    "        print('day'+str(i), 1/((day_s[i]/24)**0.5+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 3s, 0 0.195793\n",
      "training time: 3s, 1 0.239875\n",
      "training time: 3s, 2 0.167259\n",
      "training time: 3s, 3 0.224661\n",
      "training time: 2s, 4 0.249141\n",
      "training time: 2s, 5 0.185169\n",
      "training time: 3s, 6 0.180602\n",
      "training time: 3s, 7 0.119711\n",
      "training time: 3s, 8 0.08584\n",
      "training time: 3s, 9 0.079414\n",
      "training time: 3s, 10 0.081423\n",
      "training time: 3s, 11 0.080235\n",
      "training time: 3s, 12 0.063151\n",
      "training time: 3s, 13 0.07456\n",
      "training time: 4s, 14 0.074843\n",
      "training time: 3s, 15 0.065497\n",
      "training time: 4s, 16 0.087408\n",
      "training time: 3s, 17 0.083477\n",
      "training time: 2s, 18 0.095089\n",
      "training time: 3s, 19 0.127635\n",
      "training time: 3s, 20 0.111979\n",
      "training time: 3s, 21 0.127171\n",
      "training time: 3s, 22 0.146241\n",
      "training time: 3s, 23 0.178622\n",
      "day0 0.16453515222696216\n",
      "day1 0.08394894302522089\n",
      "day2 0.10338296924473202\n",
      "day3 0.10073885075969154\n",
      "day4 0.08766917610968689\n",
      "day5 0.09992240856156176\n",
      "day6 0.10326838176641459\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1 lightgbm validation\n",
    "'''\n",
    "valid_res_lgb = hour_level_flow_prediction(model='lightgbm', mode='valid')\n",
    "validation_score(valid_res_lgb, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 19s, 0 0.248742\n",
      "training time: 19s, 1 0.304806\n",
      "training time: 19s, 2 0.174643\n",
      "training time: 19s, 3 0.246755\n",
      "training time: 19s, 4 0.312536\n",
      "training time: 19s, 5 0.244585\n",
      "training time: 19s, 6 0.184857\n",
      "training time: 20s, 7 0.117175\n",
      "training time: 20s, 8 0.070074\n",
      "training time: 20s, 9 0.062884\n",
      "training time: 20s, 10 0.077374\n",
      "training time: 19s, 11 0.082666\n",
      "training time: 20s, 12 0.072598\n",
      "training time: 20s, 13 0.071438\n",
      "training time: 20s, 14 0.071335\n",
      "training time: 20s, 15 0.057189\n",
      "training time: 20s, 16 0.062647\n",
      "training time: 20s, 17 0.07221\n",
      "training time: 20s, 18 0.098431\n",
      "training time: 20s, 19 0.131058\n",
      "training time: 20s, 20 0.145595\n",
      "training time: 19s, 21 0.145167\n",
      "training time: 20s, 22 0.15643\n",
      "training time: 20s, 23 0.206404\n",
      "day0 0.15764755422935522\n",
      "day1 0.0777827215809487\n",
      "day2 0.09089254304677487\n",
      "day3 0.08966808015388396\n",
      "day4 0.0834780969069708\n",
      "day5 0.09459706818662386\n",
      "day6 0.11585549327554359\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2-1 xgboost validation\n",
    "'''\n",
    "valid_res_xgb = hour_level_flow_prediction(model='xgboost', mode='valid')\n",
    "validation_score(valid_res_xgb, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 3s, training time: 4s, training time: 3s, training time: 4s, training time: 4s, training time: 3s, training time: 3s, training time: 4s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 5s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 7, 997)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2-2 lightgbm prediction\n",
    "'''\n",
    "pred_res_lgb = hour_level_flow_prediction(model='lightgbm', mode='predict')\n",
    "pred_flow_hour_level_lgb = np.array([pred_res_lgb[h]['pred_flow'] for h in range(24)])\n",
    "pred_flow_hour_level_lgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 36s, training time: 35s, training time: 35s, training time: 35s, training time: 35s, training time: 35s, training time: 35s, training time: 37s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, training time: 36s, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 7, 997)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2-2 xgboost prediction\n",
    "'''\n",
    "pred_res_xgb = hour_level_flow_prediction(model='xgboost', mode='predict')\n",
    "pred_flow_hour_level_xgb = np.array([pred_res_xgb[h]['pred_flow'] for h in range(24)])\n",
    "pred_flow_hour_level_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2-3 save the result of hour-level prediction\n",
    "'''\n",
    "with open('./cache/pred_flow_hour_level_lgb.pkl', 'wb') as f:\n",
    "    pkl.dump(pred_flow_hour_level_lgb, f)\n",
    "with open('./cache/pred_flow_hour_level_xgb.pkl', 'wb') as f:\n",
    "    pkl.dump(pred_flow_hour_level_xgb, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. hour-level flow prediction for weekday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 2s, 0 0.155428\n",
      "training time: 2s, 1 0.176472\n",
      "training time: 2s, 2 0.146778\n",
      "training time: 2s, 3 0.241792\n",
      "training time: 2s, 4 0.226613\n",
      "training time: 2s, 5 0.18198\n",
      "training time: 2s, 6 0.120361\n",
      "training time: 2s, 7 0.111624\n",
      "training time: 3s, 8 0.079566\n",
      "training time: 3s, 9 0.091739\n",
      "training time: 2s, 10 0.091003\n",
      "training time: 3s, 11 0.091607\n",
      "training time: 2s, 12 0.093984\n",
      "training time: 2s, 13 0.097339\n",
      "training time: 2s, 14 0.094939\n",
      "training time: 2s, 15 0.09524\n",
      "training time: 2s, 16 0.098816\n",
      "training time: 3s, 17 0.088674\n",
      "training time: 3s, 18 0.099535\n",
      "training time: 3s, 19 0.122727\n",
      "training time: 3s, 20 0.141173\n",
      "training time: 3s, 21 0.136587\n",
      "training time: 3s, 22 0.136186\n",
      "training time: 2s, 23 0.116825\n",
      "day0 0.10806977728031553\n",
      "day1 0.12211402478585628\n",
      "day2 0.11343928544117438\n",
      "day3 0.10488900287534458\n",
      "day4 0.11037450352855668\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3-1 lightgbm validation for weekday\n",
    "'''\n",
    "weekday_valid_res_lgb = hour_level_flow_prediction(model='lightgbm', mode='valid', weekday=True)\n",
    "validation_score(weekday_valid_res_lgb, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 15s, 0 0.190041\n",
      "training time: 15s, 1 0.230841\n",
      "training time: 15s, 2 0.169747\n",
      "training time: 15s, 3 0.259817\n",
      "training time: 15s, 4 0.276144\n",
      "training time: 15s, 5 0.216699\n",
      "training time: 16s, 6 0.176162\n",
      "training time: 15s, 7 0.118015\n",
      "training time: 16s, 8 0.087871\n",
      "training time: 15s, 9 0.093724\n",
      "training time: 15s, 10 0.098227\n",
      "training time: 15s, 11 0.10286\n",
      "training time: 15s, 12 0.098669\n",
      "training time: 15s, 13 0.102333\n",
      "training time: 15s, 14 0.098337\n",
      "training time: 15s, 15 0.100638\n",
      "training time: 15s, 16 0.104155\n",
      "training time: 15s, 17 0.090417\n",
      "training time: 15s, 18 0.107198\n",
      "training time: 15s, 19 0.120712\n",
      "training time: 15s, 20 0.14782\n",
      "training time: 15s, 21 0.15578\n",
      "training time: 15s, 22 0.134674\n",
      "training time: 15s, 23 0.183269\n",
      "day0 0.11175302253533667\n",
      "day1 0.13290177843452544\n",
      "day2 0.12533315049670873\n",
      "day3 0.11560381784909994\n",
      "day4 0.12300675461930273\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "3-1 xgboost validation for weekday\n",
    "'''\n",
    "weekday_valid_res_xgb = hour_level_flow_prediction(model='xgboost', mode='valid', weekday=True)\n",
    "validation_score(weekday_valid_res_xgb, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 3s, training time: 3s, training time: 3s, training time: 3s, training time: 3s, training time: 3s, training time: 3s, training time: 4s, training time: 4s, training time: 5s, training time: 4s, training time: 4s, training time: 5s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, training time: 4s, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24, 5, 997)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3-2 lightgbm prediction for weekday\n",
    "'''\n",
    "weekday_pred_res_lgb = hour_level_flow_prediction(model='lightgbm', mode='predict', weekday=True)\n",
    "weekday_pred_flow_hour_level_lgb = np.array([weekday_pred_res_lgb[h]['pred_flow'] for h in range(24)])\n",
    "weekday_pred_flow_hour_level_lgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 5, 997)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "3-2 xgboost prediction for weekday\n",
    "'''\n",
    "weekday_pred_res_xgb = hour_level_flow_prediction(model='xgboost', mode='predict', weekday=True)\n",
    "weekday_pred_flow_hour_level_xgb = np.array([weekday_pred_res_xgb[h]['pred_flow'] for h in range(24)])\n",
    "weekday_pred_flow_hour_level_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3-3 save the result of hour-level prediction\n",
    "'''\n",
    "with open('./cache/weekday_pred_flow_hour_level_lgb.pkl', 'wb') as f:\n",
    "    pkl.dump(weekday_pred_flow_hour_level_lgb, f)\n",
    "with open('./cache/weekday_pred_flow_hour_level_xgb.pkl', 'wb') as f:\n",
    "    pkl.dump(weekday_pred_flow_hour_level_xgb, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
